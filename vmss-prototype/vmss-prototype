#!/usr/bin/env python
# PYTHON_ARGCOMPLETE_OK
# The token above is necessary for Python bash auto-complete trigger
# pylint: disable=line-too-long

import argparse
import datetime
import json
import logging
import os
import re
import subprocess
import sys
import threading
import time

# This is what hooks to the Python bash autocomplete
import argcomplete  # type: ignore


def fatal_error(msg):
    """
    Fail this process with the given message flushed to stderr
    :param msg: Message to be output
    :return: None
    """
    logging.critical(msg)
    sys.stderr.write('{0}\n'.format(msg))
    sys.stderr.flush()
    sys.exit(-1)


def masq_text(text, masq=None):
    """
    Masquerade any secrets in the given text
    :param text: Text to masq out secrets
    :param masq: List of strings to masquerade from the output log (useful for secrets)
    :return: The text string after masquerading secrets
    """
    m_text = str(text)
    if masq is not None:
        for masq_item in masq:
            m_text = m_text.replace(masq_item.decode() if isinstance(masq_item, bytes) else masq_item, '***')
    return m_text


def masq_cmd(command, masq=None):
    """
    Build a text version of the given command that masquerades any secrets as needed
    :param command: Command to masq, list of types that are convertible to string
    :param masq: List of strings to masquerade from the command output log (useful for secrets)
    :return: The single text string of the command after masquerading secrets and joining the command
    """
    # Note that subprocess.list2cmdline does not handle this correctly
    # Specifically, it messes up certain json query options.  This is why
    # I use this construct to do it which leaves more quotes than needed but
    # at least does not mess up the quotes where needed.
    return re.sub(r'([\'"]), ([\'"])', '\\1 \\2', str([masq_text(arg, masq=masq) for arg in command]))


def log_cmd(command, show_cmd=True, masq=None, dry_run=False, comment=None, duration=None):
    """
    Log the given command as the command we are about to execute
    :param command: Command to log, either as a string or list of types that are convertible to string
    :param show_cmd: Show the command line that is about to be executed (on stderr)
    :param masq: List of strings to masquerade from the command output log (useful for secrets)
    :param dry_run: Just echo the command, don't run it
    :return:
    """
    text = "===> {0}: {1}{2}".format('Dry run command' if dry_run else 'Executing command' if duration is None else 'Completed in {0:.2f}s'.format(duration),
                                     masq_cmd(command, masq=masq),
                                     '' if comment is None else ' # {0}'.format(comment))
    if show_cmd:
        logging.info(text)
    else:
        logging.debug(text)


def log_stdout_stderr(stdout, stderr, exit_code, masq=None):
    """
    Log the stdout, stderr, and exit_code, applying the masq as needed
    :param stdout: The stdout from a command that ran
    :param stderr: The stderr from a command that ran
    :param exit_code: The exit code (number) of a command that ran
    :param masq: List of strings to masquerade from the command output log (useful for secrets)
    :return:
    """
    log_func = lambda s: logging.warning(s) if exit_code != 0 else logging.info(s)
    if stdout.strip(' \t\n\r') != "":
        for line in stdout.splitlines():
            log_func("STDOUT: {0}".format(masq_text(line, masq)))
    if stderr.strip(' \t\n\r') != "":
        for line in stderr.splitlines():
            log_func("STDERR: {0}".format(masq_text(line, masq)))
    log_func("EXIT CODE: {0}".format(exit_code))


def run(command, timeout=None, env=None, shell=False, check=True, quiet=False, dry_run=False, show_cmd=True, cwd=None,
        echo=False, masq=None, stdin='', comment=None, log_timing=False, log_stdout_on_error=True, log_stderr_on_error=True,
        retries=1, retry_wait_duration_func=lambda num_retry: 2 ** (num_retry + 2), log_final_error=False, log_retry_errors=False,
        retry_func=lambda stdout, stderr, exit_code: True):
    """
    Run the given command in the shell
    :param command: Command vectory to execute - first entry is the command, remaining are the arguments
    :param timeout: Timeout, in seconds, to wait for command to finish
    :param env: Environment to use when running the command
    :param shell: Whether to use shell directly or not. Setting this to True is VERY dangerous, please know what you
                  are doing. The default shell is sh on Linux. However, this may be the only way to make the commands
                  with pipes work as single-shot commands.
    :param check: Throws if the error code returned is not 0
    :param quiet: Redirects all output to /dev/null
    :param dry_run: Just echo the command, don't run it
    :param show_cmd: Show the command line that is about to be executed (on stderr)
    :param cwd: working directory for Popen
    :param echo: Show output of the command before returning it to the caller
    :param masq: List of strings to masquerade from the command output log (useful for secrets)
    :param stdin: A string of data to be passed to stdin of the process - defaults to nothing
    :param comment: An optional comment to be logged with the command line
    :param log_timing: If true, logs the execution time of the command in addition to the command
    :param log_stdout_on_error: If true (default), on error, the stdout of the command is logged
    :param log_stderr_on_error: If true (default), on error, the stderr of the command is logged
    :param retries: Number of retries before giving up due to errors
    :param retry_wait_duration_func: A function to get the wait in seconds for a particular retry attempt. Default delay is exponential backoff with initial delay of 8 seconds
    :param log_final_error: Log the final retry error even if check==False
    :param log_retry_errors: Log the errors for retries
    :param retry_func: Function to call after an error.   Passed in 3-tuple (stdin, stdout, exit_code), return is if retry should happen (False if no retry)
    :return: 3-tuple (stdout as string, stderr as string and exit code as int)
    """
    stdout = ""
    stderr = ""
    exit_code = 0
    cmd = None

    if isinstance(command, list):
        cmd = [arg.decode('ascii') if isinstance(arg, bytes) else str(arg) for arg in command]
    else:
        fatal_error("The command must be a list")

    # Echo the command in the form we would try to execute it
    # This includes the above optional addition of splitting operations
    # We do a bit of formatting such that the command display is a bit nicer and
    # can be more likely cut-n-paste to execute it
    log_cmd(cmd, show_cmd=show_cmd, masq=masq, dry_run=dry_run, comment=comment)

    # If dry run is specified, simply return after echo
    if dry_run:
        return stdout, stderr, exit_code

    # If in the quiet mode, redirect all output to null; otherwise pipe so we can capture it
    if quiet:
        output = open(os.devnull, "w")
    else:
        output = subprocess.PIPE

    start_time = time.time()
    num_retry = 1
    while True:
        # clear variables
        exit_code = -100
        stdout = ""
        stderr = ""

        retry_start_time = time.time()

        # Open a process so that we can communicate with it
        p = subprocess.Popen(cmd, shell=shell, cwd=cwd, stdin=subprocess.PIPE, stdout=output, stderr=output, env=env)

        try:
            stdout, stderr = p.communicate(timeout=timeout, input=stdin if isinstance(stdin, bytes) else str(stdin).encode())
            exit_code = p.returncode
        except subprocess.TimeoutExpired:
            stderr += "\nERROR: TIMEOUT"
            p.terminate()
            exit_code = -99

        # Under certain error conditions, stdout/stderr are not bytes
        # so we need to handle that here.  (Mainly under timeout conditions)
        if isinstance(stdout, bytes):
            stdout = stdout.decode('utf-8')
        if isinstance(stderr, bytes):
            stderr = stderr.decode('utf-8')

        if exit_code == 0:
            break

        # If we are to log "retry" errors, do that here before we talk about the retry
        if log_retry_errors:
            retry_duration = time.time() - retry_start_time
            done_comment = 'RC={0}  try #{1}'.format(exit_code, num_retry)
            if comment is not None:
                done_comment = '{0} : {1}'.format(comment, done_comment)
            log_cmd(cmd, show_cmd=show_cmd, masq=masq, dry_run=dry_run, comment=done_comment, duration=retry_duration)
            log_stdout_stderr(stdout if log_stdout_on_error else '', stderr if log_stderr_on_error else '', exit_code, masq=masq)

        if num_retry >= retries:
            break

        if not retry_func(stdout, stderr, exit_code):
            break

        retry_delay = retry_wait_duration_func(num_retry)
        logging.warning("Attempt {0}: Command failed with exit code {1}.  Retrying in {2}s ...".format(num_retry, 'TIMEOUT (-99)' if exit_code == -99 else 'UNKNOWN_FAULT (-100)' if exit_code == -100 else exit_code, retry_delay))

        time.sleep(retry_delay)
        num_retry += 1

        # Log the retry of the command...
        log_cmd(cmd, show_cmd=show_cmd, masq=masq, dry_run=dry_run, comment='{0} ... try #{1}'.format(comment if comment is not None else '', num_retry))

    duration = time.time() - start_time
    if log_timing:
        done_comment = 'RC={0}'.format(exit_code)
        if comment is not None:
            done_comment = '{0} : {1}'.format(comment, done_comment)
        log_cmd(cmd, show_cmd=show_cmd, masq=masq, dry_run=dry_run, comment=done_comment, duration=duration)

    # If check is on, throw on non-zero exit code (emulate check_call behavior, but with fast fail)
    # Note that we must masq the output too as sometimes secrets can show up in the output
    if (exit_code != 0 and (check or log_final_error) and not log_retry_errors) or echo:
        log_stdout_stderr(stdout if log_stdout_on_error else '', stderr if log_stderr_on_error else '', exit_code, masq=masq)

    if exit_code != 0 and check:
        fatal_error("Unexpected exit code {0} from child process: {1}".format(exit_code, masq_cmd(cmd, masq=masq)))

    return stdout, stderr, exit_code


def get_nodes():
    """
    Get a list of nodes in the current cluster
    :return: A list of nodes
    """
    nodes, _, _ = run(['kubectl', 'get', 'nodes',
                       '--output', 'jsonpath={.items[*].metadata.name}'
                       ], retries=3)
    return nodes.split()


def is_vmss_name(vmss_name):
    """
    Returns true of the name is a valid vmss name
    :param vmss_name: A valid vmss name
    :return: True if name is a valid vmss
    """
    return re.match(r'^\S+-vmss$', vmss_name) is not None


def is_vmss_node(node_name):
    """
    Returns true of the node name is a valid vmss node name
    :param node_name: A valid vmss node name
    :return: True if node is valid vmss node
    """
    return re.match(r'^\S+-vmss[0-9a-z]{6}$', node_name) is not None


def node_to_vmss(node_name):
    """
    Convert node name to VMSS name
    :param node_name: A valid vmss node name
    :return: The name of the vmss
    """
    return re.sub(r'-vmss[0-9a-z]{6}$', r'-vmss', node_name)


def get_vmss_set():
    """
    Get the sorted list of VMSS that could be set to run prototype pattern
    :return: A set of valid VMSS for this cluster that could run prototype pattern
    """
    # The set of VMSS in the cluster
    return sorted({node_to_vmss(node) for node in get_nodes() if is_vmss_node(node)})


def get_vmss_sig(name):
    """
    Return the name of the SIG for a given unique name (usually the resource group name)
    :param name: The unique name, usually of the resource group
    :return: The name of the SIG for that cluster
    """
    # SIG names can not have "-" but can have "_"
    # SIG names also must be unique across the subscription even if
    # they are within different resource groups!
    return 'SIG_{0}'.format(name.replace('-','_'))


def get_sig_image_def(vmss_name):
    """
    Generate the SIG image definition name for the given VMSS name
    :param vmss_name:  The name of the VMSS we are looking for
    :return:  Name of the SIG image definiton
    """
    return 'kamino-{0}-prototype'.format(vmss_name)


def lookup_one_value(value_dict, value_arg):
    """
    Look up a value from a nested dictionary given the dotted string as the key
    :param value_dict: The dictionary to look into
    :param value_arg: The dotted string to look up in the dict
    :return: The value or None if not found
    """
    value = value_dict
    for part in value_arg.split("."):
        if value:
            try:
                value = value[part]
            except:
                value = None
    return value


def az(cmd, subscription=None):
    """
    Build the az command with optional subscription
    :param cmd: The AZ command as a list of words
    :param subscription: Optional subscription upon which to scope the command
    :return: A list of the first part of the command
    """
    az_cmd = ['az'] + cmd
    if subscription:
        az_cmd += ['--subscription', subscription]
    return az_cmd


def not_found_no_retry(_stdout, stderr, _exit_code):
    """
    We need this function for the retry_func in a number of places
    It stops the retries if a NotFound is the reason for the failure
    :param _stdout: The stdout of the failed command (not used)
    :param stderr: The stderr of the failed command (used)
    :param _exit_code: The exit_code of the command (not used)
    :return: True if we should retry, False if not
    """
    # Return False if we have any kind of 'NotFound'
    return 'NotFound' not in stderr


def get_vmss_images(subscription, resource_group, sig_name, image_definition):
    """
    Get the list of image versions for this given VMSS or None if none exist
    :return: A list of available versions
    """
    output, _, rc = run(az(['sig', 'image-version', 'list'], subscription) + [
                        '--resource-group', resource_group,
                        '--gallery-name', sig_name,
                        '--gallery-image-definition', image_definition
                        ], retries=3, check=False, retry_func=not_found_no_retry)
    if rc != 0:
        return None

    return json.loads(output)


def vmss_prototype_collect_status(sub_args):
    """
    Gather information about VMSS Prototype deployment in the cluster
    :param sub_args:  Command line arguments
    :return: generator of status information lines
    """
    subscription = sub_args.subscription
    resource_group = sub_args.resource_group
    sig_name = get_vmss_sig(resource_group)

    _, _, rc = run(az(['sig', 'show'], subscription) + [
                   '--resource-group', resource_group,
                   '--gallery-name', sig_name
                   ], retries=3, check=False, retry_func=not_found_no_retry)
    if rc != 0:
        yield 'No Kamino VMSS Prototype Shared Image Gallery for cluster'
        return

    for vmss in get_vmss_set():
        # The VMSS specific image definition name
        image_definition = get_sig_image_def(vmss)

        output, _, rc = run(az(['sig', 'image-definition', 'show'], subscription) + [
                            '--resource-group', resource_group,
                            '--gallery-name', sig_name,
                            '--gallery-image-definition', image_definition
                            ], retries=3, check=False, retry_func=not_found_no_retry)
        if rc != 0:
            yield '{0}: {1}: No Kamino VMSS Prototype Image Definition'.format(sub_args.resource_group, vmss)
            continue

        image_def = json.loads(output)

        versions = get_vmss_images(subscription, resource_group, sig_name, image_definition)
        if not versions:
            yield '{0}: {1}: Failed to get Kamino VMSS Prototype Image Definition Versions'.format(resource_group, vmss)
            continue

        if len(versions) < 1:
            yield '{0}: {1}: No Kamino VMSS Prototype Image Definition Versions'.format(resource_group, vmss)
            continue

        output, _, _ = run(az(['vmss', 'show'], subscription) + [
                           '--resource-group', resource_group,
                           '--name', vmss
                           ], retries=3, retry_func=not_found_no_retry)
        vmss_info = json.loads(output)

        versions.sort(key=lambda image: image['name'])
        for version in reversed(versions):
            yield '{0}: {1}: VMSS Prototype Image Version {2} - {3} - BuiltFrom: {4} @ {5}'.format(
                sub_args.resource_group,
                vmss,
                lookup_one_value(version, 'name'),
                lookup_one_value(version, 'provisioningState'),
                lookup_one_value(version, 'tags.BuiltFrom'),
                lookup_one_value(version, 'tags.BuiltAt')
                )

        image_ref = lookup_one_value(vmss_info, 'virtualMachineProfile.storageProfile.imageReference.id')
        found = False
        if image_ref == image_def['id']:
            yield '{0}: {1}: Configured to use latest VMSS Prototype Image Definition'.format(sub_args.resource_group, vmss)
            found = True
        else:
            for version in versions:
                if image_ref == version['id']:
                    yield '{0}: {1}: Configured to use VMSS Prototype Image Version {2}'.format(sub_args.resource_group, vmss, version['name'])
                    found = True

        if not found:
            yield '{0}: {1}: Not configured to use VMSS Prototype Image'.format(sub_args.resource_group, vmss)


def vmss_prototype_status(sub_args):
    """
    Display information about the VMSS prototype settings
    :param sub_args:  Command line arguments
    :return:
    """
    if not sub_args.resource_group:
        fatal_error('Must provide the resource group of the cluster!')

    # Gather the results and then print them
    results = list(vmss_prototype_collect_status(sub_args))
    print('VMSS Prototype Status for cluster:')
    for result in results:
        print(result)


def vmss_build_sig_image(subscription, resource_group, sig_name, image_definition, version, snapshot):
    """
    Try to build a SIG image version - default is ZRS unless that
    does not work, in which case it will fall back to LRS storage
    :param subscription:  The subscription the resource group is in
    :param resource_group:  The resource group of the sig
    :param sig_name:  The name of the sig
    :param image_definition:  The inmage definition name
    :param version:  The version we will be creating
    :param snapshot:  The snapshow we will be creating from
    :return:  The output yaml (as text) of the version we created
    """
    # create command without the storage account type included
    create_cmd = az(['sig', 'image-version', 'create'], subscription) + [
                 '--resource-group', resource_group,
                 '--gallery-name', sig_name,
                 '--gallery-image-definition', image_definition,
                 '--gallery-image-version', version,
                 # See https://docs.microsoft.com/en-us/azure/virtual-machines/windows/shared-image-galleries#scaling
                 '--replica-count', 3,
                 '--os-snapshot', snapshot['name'],
                 '--tags',
                    'BuiltFrom={0}'.format(snapshot['tags']['BuiltFrom']),
                    'BuiltAt={0}'.format(snapshot['tags']['BuiltAt'])
                 ]

    # Start with ZRS - if it fails, we try again with LRS
    # In regions/data centers where ZRS is not yet supported, this may take a
    # while to fail.  It seems there is no good way to be sure (other than
    # knowing somewhere) if ZRS would work.  The best answer is to try and
    # if it fails, we will fall back to LRS
    # The good thing is that once ZRS is available in a region, the next
    # image version created will be via ZRS.  The bad thing is that it takes
    # a few minutes to notice that ZRS does not work and that we have to do
    # the LRS fallback.  Given that creating an image can take an hour anyway,
    # this extra overhead is barely noticed and it is better to be automaticly
    # ZRS enabled than force the user to know the difference
    logging.info('Creating sig image version - this can take quite a long time...')
    output, err, rc = run(create_cmd + ['--storage-account-type', 'Standard_ZRS'],
                          retries=3,
                          check=False,
                          log_timing=True,
                          log_retry_errors=True,
                          retry_func=lambda stdout, stderr, exit_code: 'detail:ZRS is not supported' not in stderr)

    if rc != 0:
        if 'detail:ZRS is not supported' not in err:
            fatal_error('Could not create image version!')

        # Delete the broken image since we can't change the storage type of an
        # existing image even if it failed to create - Azure is very strange
        # here since the image failed to create and yet it still exists as
        # a failed image and must be deleted first before another attempt can
        # be made.
        run(az(['sig', 'image-version', 'delete'], subscription) + [
            '--resource-group', resource_group,
            '--gallery-name', sig_name,
            '--gallery-image-definition', image_definition,
            '--gallery-image-version', version
            ], check=False, retries=3)

        logging.warning('Creating sig image version with ZRS failed, so now creating without ZRS')
        logging.info('Creating sig image version - this can take quite a long time...')
        output, _, _ = run(create_cmd + ['--storage-account-type', 'Standard_LRS'],
                           retries=3, log_timing=True, log_retry_errors=True)

    return output


def mktime_from_kubernetes(kube_time_string):
    """
    Convert a kubernetes RFC time string into python time value
    :param kube_time_string:  The time string from a kubernetes element
    :return:  A Python time value (floating point value)
    """
    return time.mktime(time.strptime(kube_time_string, '%Y-%m-%dT%H:%M:%SZ'))


def format_into_version(date_time):
    """
    Convert a datetime into a version string
    Note that the format of the string is yyyy.mm.dd
    and is required to be in that kind of format for
    the SIG to work correctly (defined by Azure)
    It does not need to be year.month.day but it must
    be a digits.digits.digits specifically and ordered
    via the version ordering constraint.
    :param date_time: The datetime object to convert
    :return: The version string as we use within the SIG
    """
    # Format for version numbers from timestamps
    return date_time.strftime('%Y.%m.%d')


def vmss_prototype_update(sub_args):
    """
    Update (create if not existing) the prototype based images for the
    auto-scaling VMSS instances in this cluster
    :param sub_args:  Arguments from command line
    :return:
    """
    resource_group = sub_args.resource_group
    if not resource_group:
        fatal_error('Must provide the resource group of the cluster!')

    subscription = sub_args.subscription
    target_node = sub_args.target_node
    sig_name = get_vmss_sig(resource_group)

    # Check if the target node exists
    _, _, rc = run(['kubectl', 'get', 'node',
                    target_node
                    ], retries=3, check=False, retry_func=not_found_no_retry)
    if rc != 0:
        fatal_error('Could not find node {0}'.format(target_node))

    # Check if we have the Shared Image Gallery - if not, create one
    _, _, rc = run(az(['sig', 'show'], subscription) + [
                   '--resource-group', resource_group,
                   '--gallery-name', sig_name
                   ], retries=3, check=False, retry_func=not_found_no_retry)

    if rc != 0:
        run(az(['sig', 'create'], subscription) + [
            '--resource-group', resource_group,
            '--gallery-name', sig_name,
            '--description', 'Kamino VMSS images'
            ], retries=3)

    # Pod types we will skip during drain/delete
    pod_types_to_skip = ['DaemonSet', 'Node']

    # The time format we use in snapshot tags
    snapshot_time_format = '%Y-%m-%d %H:%M:%S.%f'

    vmss = node_to_vmss(target_node)
    logging.info('Processing VMSS {0}'.format(vmss))

    # To get a managed image, we need to first create a snapshot from the
    # VMSS.  This is the name of that snapshot.  We will delete it once
    # the new image is in place.
    snapshot_name = 'snapshot_{0}'.format(vmss)

    # Create our version number from the managed image
    version = format_into_version(datetime.datetime.now())

    # The VMSS specific image definition name
    image_definition = get_sig_image_def(vmss)

    # Now, we need a image-definition for this VMSS
    output, _, rc = run(az(['sig', 'image-definition', 'show'], subscription) + [
                        '--resource-group', resource_group,
                        '--gallery-name', sig_name,
                        '--gallery-image-definition', image_definition
                        ], retries=3, check=False, retry_func=not_found_no_retry)
    if rc != 0:
        output, _, _ = run(az(['sig', 'image-definition', 'create'], subscription) + [
                           '--resource-group', resource_group,
                           '--gallery-name', sig_name,
                           '--gallery-image-definition', image_definition,
                           '--publisher', 'VMSS-Prototype-Pattern',
                           '--offer', sub_args.resource_group,
                           '--sku', vmss,
                           '--os-type', 'Linux',
                           '--os-state', 'generalized'
                           ], retries=3)
    image_data = json.loads(output)

    # Now lets look at what versions we have have
    # We will check if we have the version for our target and
    # set the image_version to point at it.
    # We also handle bad deployments here by deleting them.
    # (Note that deployments still in creating state are
    # special and need to be "ignored" until they complete or fail)
    rc = 1
    image_version = None
    while rc != 0:
        output, _, rc = run(az(['sig', 'image-version', 'list'], subscription) + [
                            '--resource-group', resource_group,
                            '--gallery-name', sig_name,
                            '--gallery-image-definition', image_definition
                            ], retries=3, retry_func=not_found_no_retry)

        existing_versions = json.loads(output)
        existing_versions.sort(key=lambda image: image['name'])
        for existing_version in existing_versions:
            if not existing_version['provisioningState'] in ['Creating', 'Succeeded']:
                logging.info('Bad provisioning state: {0} - Cleaning up'.format(existing_version['provisioningState']))
                run(az(['sig', 'image-version', 'delete'], subscription) + [
                    '--resource-group', resource_group,
                    '--gallery-name', sig_name,
                    '--gallery-image-definition', image_definition,
                    '--gallery-image-version', existing_version['name']
                    ], check=False)
            else:
                if existing_version['name'] == version:
                    image_version = existing_version

    if not image_version:
        # Check if we have a current snapshot
        snapshot = None
        output, _, rc = run(az(['snapshot', 'show'], subscription) + [
                            '--resource-group', resource_group,
                            '--name', snapshot_name
                            ], retries=3, check=False, retry_func=not_found_no_retry)
        if rc == 0:
            # We have a snapshot - we need to now check if it is too old
            snapshot = json.loads(output)
            snapshot_date = lookup_one_value(snapshot, 'tags.BuiltAt')
            snapshot_version = format_into_version(datetime.datetime.strptime(snapshot_date, snapshot_time_format))

            if snapshot_version != version:
                # Clean up the snapshot as it is too old - we will need to
                # make a fresh one.
                run(az(['snapshot', 'delete'], subscription) + [
                    '--resource-group', resource_group,
                    '--name', snapshot_name
                    ], retries=3, retry_func=not_found_no_retry)
                snapshot = None

        # If we don't have a snapshot, we need to find if we have a node
        # from which to make one.  If not, we will end up skipping this VMSS
        if not snapshot:
            # Get some details as to this VM instance
            instance_id = int(target_node[-6:], base=36)

            output, _, _ = run(az(['vmss', 'show'], subscription) + [
                               '--resource-group', resource_group,
                               '--name', vmss,
                               '--instance-id', instance_id
                               ], retries=3, retry_func=not_found_no_retry)
            vmss_node_data = json.loads(output)
            vmss_disk = vmss_node_data['storageProfile']['osDisk']['managedDisk']['id']

            # Stop the cluster from scaling away the node...
            # While we are creating the snapshot it would be bad if
            # the node was deleted!
            run(['kubectl', 'annotate', 'node',
                 target_node,
                 'cluster-autoscaler.kubernetes.io/scale-down-disabled=true',
                 '--overwrite'
                 ], retries=3, retry_func=not_found_no_retry)

            nodeDeleted = False
            try:
                # Gracefully stop workloads on this VM.
                run(['kubectl', 'cordon',
                     target_node
                     ], retries=3, retry_func=not_found_no_retry)

                _, _, rc = run(['kubectl', 'drain',
                                '--ignore-daemonsets',
                                '--delete-local-data',
                                '--force',
                                '--grace-period', sub_args.grace_period,
                                '--timeout', '{0}s'.format(sub_args.grace_period * 3),
                                target_node
                                ], check=False, retries=3, log_timing=True, timeout=60 + sub_args.grace_period * 9)

                if rc != 0:
                    if not sub_args.force:
                        fatal_error('Could not drain node {0}'.format(target_node))

                    # Move any none-daemonset (or node) pods off of this node that have not
                    # drained (they should have drained already but just in case)
                    pods, _, _ = run(['kubectl', 'get', 'pods',
                                      '--all-namespaces',
                                      '--output', 'jsonpath={{range .items[?(@.spec.nodeName=="{0}")]}}{{.metadata.ownerReferences[0].kind}}{{" "}}{{.metadata.namespace}}{{" "}}{{.metadata.name}}{{"\\n"}}{{end}}'.format(target_node)
                                      ], retries=3)

                    for line in pods.splitlines():
                        (pod_type, namespace, pod) = line.split(' ')
                        if pod_type not in pod_types_to_skip:
                            run(['kubectl', 'delete', 'pod',
                                 '--force',
                                 '--namespace', namespace,
                                 pod
                                 ], retries=3, check=False, retry_func=not_found_no_retry)

                # Stop the VM now (deallocate it such that the disk image can be accessed)
                run(az(['vmss', 'deallocate'], subscription) + [
                    '--resource-group', resource_group,
                    '--name', vmss,
                    '--instance-ids', instance_id
                    ], retries=3, log_timing=True, retry_func=not_found_no_retry)

                # Snapshot the disk
                output, _, _ = run(az(['snapshot', 'create'], subscription) + [
                                   '--resource-group', resource_group,
                                   '--name', snapshot_name,
                                   '--source', vmss_disk,
                                   '--tags',
                                       'BuiltFrom={0}'.format(target_node),
                                       'BuiltAt={0}'.format(datetime.datetime.now().strftime(snapshot_time_format))
                                   ], retries=6)
                snapshot = json.loads(output)

                # Delete the instance to prevent idns side-effects from future VMs coming online based on its prototype
                # See https://github.com/jackfrancis/kamino/issues/26
                stdout, stderr, exit_code = run(az(['vmss', 'delete-instances'], subscription) + [
                    '--resource-group', resource_group,
                    '--name', vmss,
                    '--instance-ids', instance_id,
                    '--no-wait'
                    ], retries=3, check=False, retry_func=not_found_no_retry)
                if exit_code == 0:
                    nodeDeleted = True

            finally:
                if not nodeDeleted:
                    # Let it be a productive member of the cluster again
                    # We ignore errors here since the VM may no longer exist
                    # We best-effort uncordon it.
                    run(['kubectl', 'uncordon',
                        target_node
                        ], retries=3, check=False, retry_func=not_found_no_retry)

                    # Allow the cluster from scaling away the node...
                    run(['kubectl', 'annotate', 'node',
                        target_node,
                        'cluster-autoscaler.kubernetes.io/scale-down-disabled-'
                        ], retries=3, check=False, retry_func=not_found_no_retry)

        # Build the image version from the snapshow we have
        output = vmss_build_sig_image(subscription, resource_group, sig_name, image_definition, version, snapshot)
        image_version = json.loads(output)

        # Clean up the snapshot now that we have fully put it into the
        # shared image gallery.
        run(az(['snapshot', 'delete'], subscription) + [
            '--resource-group', resource_group,
            '--name', snapshot_name
            ], retries=3, retry_func=not_found_no_retry)

    logging.info('Latest image: {0}'.format(image_version['id']))

    # Now, lets clean up extra images (more than last two)
    output, _, _ = run(az(['sig', 'image-version', 'list'], subscription) + [
                       '--resource-group', resource_group,
                       '--gallery-name', sig_name,
                       '--gallery-image-definition', image_definition
                       ], retries=3)
    versions = json.loads(output)

    # Prune versions older than the newest n
    # First, sort by the version
    versions.sort(key=lambda image: image['name'])
    while len(versions) > sub_args.max_history:
        old_image = versions.pop(0)
        old_version = old_image['name']
        logging.info('Pruning old {0} image version {1}'.format(vmss, old_version))
        # We don't care if it fails as we will catch them next time
        run(az(['sig', 'image-version', 'delete'], subscription) + [
            '--resource-group', resource_group,
            '--gallery-name', sig_name,
            '--gallery-image-definition', image_definition,
            '--gallery-image-version', old_version
            ], check=False)

    # We should be able to only need to do this once per VMSS since after
    # that the VMSS points at our image definition.  This does not take long
    # and if it matches what was already there, we don't re-apply the
    # setting.
    output, _, _ = run(az(['vmss', 'show'], subscription) + [
                       '--resource-group', resource_group,
                       '--name', vmss
                       ], retries=3)
    vmss_info = json.loads(output)
    if lookup_one_value(vmss_info, 'virtualMachineProfile.storageProfile.imageReference.id') == image_data['id']:
        logging.info('VMSS {0} already set up to use prototype image'.format(vmss))
    else:
        # When we set up the new image to be from a snapshot, we must
        # remove references to the public image gallery offer.
        # We also want to turn off any cloud-config custom data as
        # the image is already configured as we need.
        # Amazingly, this command can return failure even if it works
        # so we can not trust the return result but rather must inspect
        # the VMSS configuration afterwards to see if it actually
        # worked.
        run(az(['vmss', 'update'], subscription) + [
            '--resource-group', resource_group,
            '--name', vmss,
            '--set',
                'virtualMachineProfile.storageProfile.imageReference.id={0}'.format(image_data['id']),
                'virtualMachineProfile.storageProfile.imageReference.sku=null',
                'virtualMachineProfile.storageProfile.imageReference.offer=null',
                'virtualMachineProfile.storageProfile.imageReference.publisher=null',
                'virtualMachineProfile.storageProfile.imageReference.version=null',
                # This puts a no-op customData as the node is already "set" '#cloud-config\n' encoded into base64
                'virtualMachineProfile.osProfile.customData=I2Nsb3VkLWNvbmZpZwo=',
            ], retries=3, check=False)

        # This is where we again check the vmss to see if the setting actually
        # took place.  It is sad that we can not trust the above command to
        # have valid exit codes but actual evidence in the field shows that
        # it does "succeed" in setting up the settings but signal "failure"
        output, _, _ = run(az(['vmss', 'show'], subscription) + [
                           '--resource-group', resource_group,
                           '--name', vmss
                           ], retries=3)
        vmss_info = json.loads(output)
        if lookup_one_value(vmss_info, 'virtualMachineProfile.storageProfile.imageReference.id') != image_data['id']:
            fatal_error('VMSS {0} failed to be configured to use prototype iamge'.format(vmss))

    # Get the VMSS extensions and see if we can clean them up
    output, _, _ = run(az(['vmss', 'extension', 'list'], subscription) + [
                       '--resource-group', resource_group,
                       '--vmss-name', vmss
                       ], retries=3)
    extensions = json.loads(output)

    for extension in extensions:
        # Now that we have a disk image that already has all of our
        # provisioning bits on it (prototype) we can remove all extensions
        # But...  We want to keep the billing one for telemetry reasons
        # It is a no-op code wise but gives counts
        if 'vmss-computeAksLinuxBilling' not in extension['name']:
            run(az(['vmss', 'extension', 'delete'], subscription) + [
                '--resource-group', resource_group,
                '--vmss-name', vmss,
                '--name', extension['name']
                ], retries=3, check=False, retry_func=not_found_no_retry)

    if sub_args.new_updated_nodes > 0:
        # Scale out 1 more VMSS instance to replace the previously deleted instance
        # Note: this does not respect any changes that may have occured to the VMSS instance count during update
        # from out-of-band node scaling tools such as cluster-autoscaler
        output, _, _ = run(az(['vmss', 'show'], subscription) + [
                        '--resource-group', resource_group,
                        '--name', vmss
                        ], retries=3)
        vmss_info = json.loads(output)
        capacity = lookup_one_value(vmss_info, 'sku.capacity')
        if capacity != None:
            # Increase the capacity of the VMSS by the value of --new-updated-nodes
            run(az(['vmss', 'update'], subscription) + [
                '--resource-group', resource_group,
                '--name', vmss,
                '--set',
                    'sku.capacity={0}'.format(capacity + sub_args.new_updated_nodes),
                "--no-wait"
                ], retries=3, check=False)
        else:
            logging.warning('Unable to determine capacity for VMSS {0}, will not add back 1 instance'.format(vmss))


def get_candidate_nodes(vmss, nodes, node_ignore_names, node_ignore_annotations, minimum_ready_time, pending_reboot_annotation, last_patch_annotation, latest_image):
    """
    Returns an ordered list of candidates, with the longest healthy first.
    Candidates are nodes names for the "prototype" node.
    This may be an empty list which would mean that there are no valid candidates.
    :param vmss:  The name of the VMSS we are operating on
    :param nodes:  The Nodes items from kubernetes
    :param node_ignore_names:  The list of node names to ignore
    :param node_ignore_annotations:  The list of node annotations that, if existing, will cause the node to be ignored
    :param minimum_ready_time:  Minimum ready time before a node is considered
    :param pending_reboot_annotation:  The annotation on a node that signals it is pending a reboot
    :param latest_patch_annotation:  The annotation on a node that holds the date/time of the last OS patch update
    :latest_image:  The version string of the current latest image (or None, if OS patch should not be considered)
    :return:  An list of those nodes that passed the qualifying criteria
    """
    candidates = []
    for node in nodes:
        metadata = node.get('metadata', {})
        # If not a node in target VMSS, continue...
        node_name = metadata.get('name', 'unknown')
        if vmss not in node_name:
            logging.debug('IGNORED: Node {0} not part of vmss {1}'.format(node_name, vmss))
            continue

        if node_name == os.getenv('NODE_ID', None):
            logging.debug('IGNORED: Node {0} is the same as the node we are running on'.format(node_name))
            continue

        if node_name in node_ignore_names:
            logging.debug('IGNORED: Node {0} is in the set of specific notes to ignore'.format(node_name))
            continue

        if node.get('spec', {}).get('unschedulable', False):
            logging.debug('IGNORED: Node {0} as it is marked unschedulable'.format(node_name))
            continue

        # Filtering out masters normally is not needed unless they are, for
        # some reason, within a VMSS.  We still don't want to make fresh images
        # here as masters are a bit special.
        if metadata.get('labels', {}).get('kubernetes.io/role', '') == 'master':
            logging.debug('IGNORED: Node {0} is a control plane node'.format(node_name))
            continue

        annotations = metadata.get('annotations', {})

        ignore = [annotation for annotation in node_ignore_annotations if annotation in annotations]
        if ignore:
            logging.debug('IGNORED: Node {0} is annotated as needing to be ignored: {1}'.format(node_name, ignore))
            continue

        if pending_reboot_annotation in annotations:
            logging.debug('IGNORED: Node {0} is annotated as pending reboot: {1}'.format(node_name, pending_reboot_annotation))
            continue

        if latest_image:
            last_patch = annotations.get(last_patch_annotation, None)
            if not last_patch:
                logging.debug('IGNORED: Node {0} does not have a last patch annotation: {1}'.format(node_name, last_patch_annotation))
                continue

            last_patch_date_match = re.search(r'\d\d\d\d-\d\d-\d\d', last_patch)
            if not last_patch_date_match:
                logging.debug('IGNORED: Node {0} last patch annotation does not have a valid format: {1}={2}'.format(node_name, last_patch_annotation, last_patch))
                continue

            patch_version = last_patch_date_match.group(0).replace('-', '.')
            if patch_version <= latest_image:
                logging.debug('IGNORED: Node {0} latest patch of {1} not newer that latest image version {2}'.format(node_name, patch_version, latest_image))
                continue

        ready_time = None
        for condition in node.get('status', {}).get('conditions', []):
            if condition.get('type', '') == 'Ready':
                if condition.get('status', '') == 'True':
                    ready_time = int(mktime_from_kubernetes(condition['lastHeartbeatTime']) - mktime_from_kubernetes(condition['lastTransitionTime']))
                break
        if not ready_time:
            logging.debug('IGNORED: Node {0} is not ready'.format(node_name))
            continue

        if ready_time < minimum_ready_time:
            logging.debug('IGNORED: Node {0} has been ready for only {1}s and the minimum is {2}s'.format(node_name, ready_time, minimum_ready_time))
            continue

        logging.debug('CANDIDATE: Node {0} ready for {1}s'.format(node_name, ready_time))
        candidates.append({'node': node_name, 'ready': ready_time})

    candidates.sort(key=lambda data: data['ready'], reverse=True)
    return [candidate['node'] for candidate in candidates]


def vmss_prototype_auto_update(sub_args):
    """
    Auto update the VMSS (or set of VMSS) in the cluster if needed and ready
    :param sub_args: The command line arguments
    """
    subscription = sub_args.subscription
    resource_group = sub_args.resource_group
    sig_name = get_vmss_sig(resource_group)

    if sub_args.target_vmss:
        vmss_names = sorted(set([name for names in sub_args.target_vmss for name in names]))
    else:
        # Get all of the VMSSes in this cluster
        vmss_names = get_vmss_set()

    # Get the set of unique annotations that would trigger a skip
    node_ignore_annotations = set([name for names in sub_args.node_ignore_annotation for name in names]) if sub_args.node_ignore_annotation else set()

    # Get the set of unique node names that should be ignored
    node_ignore_names = set([name for names in sub_args.ignore_nodes for name in names]) if sub_args.ignore_nodes else set()

    # Get the total node data such that we can make some judgements as to fitness
    all_nodes_json, _, _ = run(['kubectl', 'get', 'nodes',
                                '--output', 'json'
                                ], retries=3)

    nodes = json.loads(all_nodes_json)['items']

    # The list of threads we started
    started_threads = []

    for vmss in vmss_names:
        # The VMSS specific image definition name
        image_definition = get_sig_image_def(vmss)

        versions = get_vmss_images(subscription, resource_group, sig_name, image_definition)
        # If we don't have one, any version is newer than this :-)
        latest_image = '0000.00.00'
        if versions:
            for version in versions:
                if version['name'] > latest_image:
                    latest_image = version['name']
        logging.debug('Latest image for VMSS {0} is {1}'.format(vmss, latest_image))

        # Get a list of candidate nodes with newer OS patches than the current
        # image version
        potential_nodes = get_candidate_nodes(vmss, nodes,
                                              node_ignore_names,
                                              node_ignore_annotations,
                                              sub_args.minimum_ready_time,
                                              sub_args.pending_reboot_annotation,
                                              sub_args.last_patch_annotation,
                                              latest_image)

        if len(potential_nodes) < sub_args.minimum_candidates and sub_args.maximum_image_age > 0:
            if latest_image < format_into_version(datetime.datetime.now() - datetime.timedelta(days=sub_args.maximum_image_age)):
                # We have an image older than maximum_image_age and we did not
                # find OS patches that would satisfy the constraint so
                # lets try again without looking for OS patches.
                logging.info('Image maximum age reached - looking for any suitible node')
                potential_nodes = get_candidate_nodes(vmss, nodes,
                                                      node_ignore_names,
                                                      node_ignore_annotations,
                                                      sub_args.minimum_ready_time,
                                                      sub_args.pending_reboot_annotation,
                                                      sub_args.last_patch_annotation,
                                                      None)

        if len(potential_nodes) < sub_args.minimum_candidates:
            logging.info('IGNORED: VMSS {0}: Found {1} candidates - minimum candidates is {2}'.format(vmss, len(potential_nodes), sub_args.minimum_candidates))
            continue

        # We could try multiple different instances but the first one one the
        # list is usually just fine.  (Longest "healthy" state)
        candidate_node = potential_nodes[0]
        logging.info('VMSS {0}: Picked candiate node {1} from {2} candidates'.format(vmss, candidate_node, len(potential_nodes)))
        cmd = [
                os.path.realpath(__file__),
                '--log-level', sub_args.log_level,
                '--log-prefix', vmss,
                'update',
                '--resource-group', sub_args.resource_group,
                '--new-updated-nodes', sub_args.new_updated_nodes,
                '--max-history', sub_args.max_history,
                '--grace-period', sub_args.grace_period,
                '--target-node', candidate_node
        ]

        if sub_args.subscription:
            cmd += ['--subscription', sub_args.subscription]

        if sub_args.force:
            cmd += ['--force']

        # Log what we are about to run as an update command
        log_cmd(cmd, dry_run=sub_args.dry_run)

        if not sub_args.dry_run:
            # A bit of trickery - we launch a thread to run subprocess.call() such that
            # it can run in the background while we move forward.  We do this such that
            # if there are multiple pools, they can be processed in parallel
            thread = threading.Thread(target=subprocess.call, args=([str(arg) for arg in cmd],))
            thread.daemon = False
            thread.start()
            started_threads.append(thread)

    for thread in started_threads:
        thread.join()

    # Now render the status of our system, just because
    cmd = [
        os.path.realpath(__file__),
        'status',
        '--resource-group', sub_args.resource_group
    ]
    if sub_args.subscription:
        cmd += ['--subscription', sub_args.subscription]
    status, _, _ = run(cmd, check=False)
    print(status)


def in_cluster(sub_args, func):
    """
    Check for in-cluster behavior and do the that to set up some values in the
    arguments before calling the given func
    :param sub_args: The sub_args as given from the command line
    :param func: The function to complete the operation
    """
    if sub_args.in_cluster:
        with open('/etc/kubernetes/azure.json', 'r') as azure_json_file:
            data = json.load(azure_json_file)
        username = data['aadClientId']
        password = data['aadClientSecret']
        tenant = data['tenantId']
        subscription = data['subscriptionId']
        resource_group = data['resourceGroup']

        # We have to set our default cloud (the public cloud is the default-default)
        cloud = data['cloud']

        # NOTE!  We have some remapping needs of the cloud name.
        #        The problem is that the cloud name as stored in this json does
        #        not match the cloud name that is used by azure CLI!
        # NOTE!  'AzurePublicCloud' must be mapped to 'AzureCloud'
        # NOTE!  'AzureUSGovernmentCloud' must be mapped to 'AzureUSGovernment'
        remapping = {
            'AzurePublicCloud': 'AzureCloud',
            'AzureUSGovernmentCloud': 'AzureUSGovernment'
        }
        cloud = remapping.get(cloud, cloud)

        # For air-gapped clouds, CustomCloudProfile needs to be specified in api-model
        # when CustomCloudProfile is specified in api-model, aks engine produces azure.json
        # with "cloud":"AzureStackCloud" and azurestackcloud.json with cloud name specified
        # in the CustomCloudProfile
        # https://github.com/Azure/aks-engine/pull/3063

        if cloud == "AzureStackCloud":
            with open('/etc/kubernetes/azurestackcloud.json', 'r') as azurestackfile:
                azurestackdata = json.load(azurestackfile)

            cloud = azurestackdata['name']

            # check if custom cloud is already registered
            registered_cloud, _, _ = run(["az", "cloud", "list",
                                          "--output", "tsv",
                                          "--query", "[?@.name == '{0}'].name".format(cloud)
                                          ])

            # registered_cloud comes with trainling white space, so remove it
            if registered_cloud.strip() != cloud:
                # cloud is not registered
                # Register the cloud
                run(['az', 'cloud', 'register',
                     '--name', cloud,
                     '--endpoint-active-directory', azurestackdata['activeDirectoryEndpoint'],
                     '--endpoint-active-directory-graph-resource-id', azurestackdata['graphEndpoint'],
                     '--endpoint-active-directory-resource-id', azurestackdata['resourceManagerEndpoint'],
                     '--endpoint-management', azurestackdata['serviceManagementEndpoint'],
                     '--endpoint-resource-manager', azurestackdata['resourceManagerEndpoint'],
                     '--suffix-acr-login-server-endpoint', azurestackdata['containerRegistryDNSSuffix'],
                     '--suffix-keyvault-dns', azurestackdata['keyVaultDNSSuffix'],
                     '--suffix-storage-endpoint', azurestackdata['storageEndpointSuffix']
                     ])

        run(['az', 'cloud', 'set',
             '--name', cloud
             ])

        login_cmd = ['az', 'login',
                     '--username', username,
                     '--password', password,
                     '--tenant', tenant,
                     '--service-principal'
                     ]
        if username == "msi":
            login_cmd = ['az', 'login', '--identity']
        masq = [username, password, tenant]

        # We have seen temporary network failures cause this to fail so we will
        # add a simple retry loop here, with slowly increasing delay between
        # each retry.
        run(login_cmd, retries=10, masq=masq, retry_wait_duration_func=lambda num_retry: 5 * num_retry + 1)

        run(['az', 'account', 'set',
             '--subscription', subscription
             ])

        sub_args.subscription = subscription
        sub_args.resource_group = resource_group

    return func(sub_args)


def value_minimum_check(v, minimum, name='Value'):
    """
    Ensure that the v is an int of at least minimum value
    :param v: The input to be validated
    :param minimum: The minimum legal value
    :param name: The name to call the "value" in case of error
    """
    if isinstance(v, str):
        if not v.isdigit():
            raise argparse.ArgumentTypeError('{0} must be a number that is at least {0}'.format(name, minimum))
    v = int(v)
    if v < minimum:
        raise argparse.ArgumentTypeError("{0} must be at least {1}".format(name, minimum))
    return v


def VmssName(v):
    """
    VMSS Name validation type for argparser
    :param v: The proposed vmss name
    :return: The vmss name if it fits within naming constraints
    """
    if not is_vmss_name(v):
        raise argparse.ArgumentTypeError("VMSS name must be something like:  eg k8s-pool-131414-vmss")
    return v


def NodeName(v):
    """
    VMSS Node Name validation type for argparser
    :param v: The proposed node name
    :return: The node name if it fits within naming constraints
    """
    if not is_vmss_node(v):
        raise argparse.ArgumentTypeError("Node name must be a vmss node:  eg k8s-pool-131414-vmss0003ax")
    return v


def LogPrefix(v):
    """
    Log prefix validation - prefix must not have spaces or ":"
    :param v: The proposed prefix
    :return: The prefix if it fits within naming constraints
    """
    v = str(v)
    if ':' in v:
        raise argparse.ArgumentTypeError("Log prefix must not have a ':' in it")
    if ' ' in v:
        raise argparse.ArgumentTypeError("Log prefix must not have a space in it")
    return v


def NewUpdatedNodes(v):
    """
    new-updated-nodes validation type for argparser
    :param v: The proposed new-updated-nodes value
    :return: The validated new-updated-nodes
    """
    return value_minimum_check(v, 0, 'New updated nodes')


def SubscriptionId(v):
    """
    Subscription ID (guid) validation type for argparser: 3a96ef56-41a9-40a0-b0f3-fb125c2b8798
    :param v: The proposed subscription ID
    :return: The subscription ID
    """
    if re.match(r'^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$', v) is None:
        raise argparse.ArgumentTypeError("Subscription IDs must be in the form of a GUID '12345678-1234-1234-1234-1234567890ab'")
    return v


def HistorySize(v):
    """
    Ensure that history size is a number and is at least 2
    :param v: The proposed history size
    :return: The history size
    """
    return value_minimum_check(v, 2, 'History size')


def MinimumCandidates(v):
    """
    Ensure that minimum candidates is a number and is at least 1
    :param v: The proposed minimum
    :return: The minimum
    """
    return value_minimum_check(v, 1, 'Minimum candidates')


def MaximumImageAge(v):
    """
    Ensure that we have an int value that is the maximum number of days
    an image can be before we create a fresh one even without an OS Patch
    Zero means "no maximum age" - must not be negative.
    :param v: The proposed maximum
    :return: The maximum
    """
    return value_minimum_check(v, 0, 'Maximum image age')


def MinimumReadyTime(v):
    """
    The minimum time for a node to be healthy.  This returns the number
    in seconds (int) but supports modifiers such that you can do 5m for
    5 minutes and 2h for 2 hours and 3d for 3 days.  (Or 12s for 12 seconds)
    If no modifier, we assume seconds
    :param v: The proposed minimum ready state
    :return: The minimum ready time in seconds
    """
    factor = 1
    if len(v) > 0:
        if v[-1] == 's':
            v = v[:-1]
            factor = 1
        elif v[-1] == 'm':
            v = v[:-1]
            factor = 60
        elif v[-1] == 'h':
            v = v[:-1]
            factor = 60 * 60
        elif v[-1] == 'd':
            v = v[:-1]
            factor = 60 * 60 * 24
    v = int(v) * factor
    if v < 0:
        raise argparse.ArgumentTypeError("Value must not be non-negative")
    return v


def add_command(subparsers, command, func, description=None):
    """
    Add a command to the command parsers with the given function
    and description with the common arguments needed
    :param subparsers: The subparsers to add the command to
    :param command: The command text
    :param func: The function to call for this command
    :param description: The optional description
    :return: The parser for the command that was added
    """
    parser = subparsers.add_parser(command, description=description, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.set_defaults(func=lambda sub_args: in_cluster(sub_args, func))

    # We need the resource group of the cluster.  When --in-cluster, this is
    # discovered from the azure.json cluster definition file on the node
    parser.add_argument("-g", "--resource-group", default=None, type=str,
                        help="Name of the resource group the cluster is in (required if not --in-cluster)")

    # We take a subscription in case the user has access to more than one in the
    # az cli - since we need to pick the right subscription.  When --in-cluster,
    # this is discovered from the azure.json cluster definition file on the node
    parser.add_argument("-s", "--subscription", default=None, type=SubscriptionId,
                        help="The subscription guid for the cluster's resource group (required if not --in-cluster)")

    return parser


def add_update_command(subparsers, command, func, description=None):
    """
    Add an update command to the command parsers with the given function
    and description with the common arguments needed
    :param subparsers: The subparsers to add the command to
    :param command: The command text
    :param func: The function to call for this command
    :param description: The optional description
    :return: The parser for the command that was added
    """
    parser = add_command(subparsers, command, func, description=description)
    parser.add_argument('--new-updated-nodes', default=0, type=NewUpdatedNodes,
                        help='Number of new nodes to add to the cluster after the VMSS has been updated from the prototype node (default: %(default)s)')
    parser.add_argument('--max-history', default=3, type=HistorySize,
                        help='Number of entries to keep in history - minimum is 2 - (default: %(default)s)')
    parser.add_argument('--grace-period', type=int, default=300,
                        help='Grace period in seconds for drain (default: %(default)s)')
    parser.add_argument('--force', default=False, action='store_true',
                        help='Force using target node even if drain fails')
    return parser


def register_commands(subparser):
    """
    Register commands with the parser
    :param subparser: the sub parser
    :return: True if the command was added
    """
    parser = add_command(subparser, "status", func=vmss_prototype_status,
                         description='Show status of VMSS Prototype Pattern')

    parser = add_update_command(subparser, "update", func=vmss_prototype_update,
                                description='Set up new/updated prototype')
    parser.add_argument('--target-node', required=True, type=NodeName,
                        help='Target node to use as the prototype source')

    parser = add_update_command(subparser, "auto-update", func=vmss_prototype_auto_update,
                                description='Automatically set up new/updated prototype if needed')
    parser.add_argument('--target-vmss', action='append', nargs='+', type=VmssName,
                        help='Target VMSS pools (all if not given)')
    parser.add_argument('--pending-reboot-annotation', required=True, type=str,
                        help='The name of the annotation that, if it exists, the node is pending reboot')
    parser.add_argument('--last-patch-annotation', required=True, type=str,
                        help='The name of the annotation that holds the timestamp at which the last patch was applied')
    parser.add_argument('--node-ignore-annotation', action='append', nargs='+', required=False, type=str,
                        help='Optional annotations, that if it exists, will disqualify the node as a potential candidate')
    parser.add_argument('--minimum-ready-time', default=60, type=MinimumReadyTime,
                        help='Minimum time a node must in ready state before it is considered a candidate (default %(default)s)')
    parser.add_argument('--minimum-candidates', default=1, type=MinimumCandidates,
                        help='Minimum number of acceptable candidates (default: %(default)s)')
    parser.add_argument('--maximum-image-age', default=0, type=MaximumImageAge,
                        help='Maximum number of days old a prototype image should be before a replacement is made even without OS patches (0==no maximum) (default: %(default)s)')
    parser.add_argument('--ignore-nodes', action='append', nargs='+', required=False, type=NodeName,
                        help='The name of nodes that should be ignored as potential prototype candidates')
    parser.add_argument('--dry-run', default=False, action='store_true',
                        help='Do not actually execute the update, just show what would happen')


def set_better_help(sub_parser):
    """
    Setup a better help display for sub-commands
    :param sub_parser:  The sub-parser that has sub-commands that we wish to improve
    """
    choices = [choice for choice in sub_parser.choices]
    if len(choices) > 0:
        choices.sort()
        sub_help='\none of:'
        width = 0
        for i in choices:
            width = max(width, len(i))
        for i in choices:
            sub_help += '\n\t{0}'.format(i)
            description = sub_parser.choices[i].description
            if description:
                line = description.find('\n')
                if line >= 0:
                    description = description[0:line]
                sub_help += '  {0}{1}'.format(' '*(width - len(i)), description)
        sub_parser.dest = sub_help + '\n'
        sub_parser.container.description = sub_help
        sub_parser.required = True

        # Look for any nested subparsers
        for i in choices:
            try:
                if sub_parser.choices[i]._subparsers is not None:  # pylint: disable=protected-access
                    group = sub_parser.choices[i]._subparsers._group_actions  # pylint: disable=protected-access
                    if len(group) == 1:
                        set_better_help(group[0])
            except:
                pass


def main():
    """
    The main entry point that sets up the command line parser, parses the
    command line, and then runs what the command line produced.
    """
    # Quick logging of the raw command line to scm before anything can use it/fail
    # This includes the whole command line as at the point this starts (logging is not
    # available yet, so this goes to stderr)
    sys.stderr.write('CMD: {0}\n'.format(masq_cmd(sys.argv)))

    # Start building our command line parser objects
    parser = argparse.ArgumentParser(
        description="VMSS Prototype Pattern Tool",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="\nexample use: \n\
  {0} status ...\n\n\
  More information available here: https://speechwiki.azurewebsites.net/architecture/skyman-vmss-prototype-pattern.html\n\
    ".format(sys.argv[0])
    )

    # Log level settings happen at the global level
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
                        default='INFO',
                        help="Set the logging level (default: %(default)s)")

    parser.add_argument('--log-prefix', default=None, type=LogPrefix)

    parser.add_argument('--log-timestamps', default=False, action='store_true',
                        help='Include timestamps in the logging output')

    parser.add_argument("--in-cluster", default=False, action='store_true',
                        help="Use azure.json to set up state (including subscription, resource group, and azure access)")

    subparser = parser.add_subparsers(title="commands")

    # Register our commands
    register_commands(subparser)

    set_better_help(subparser)

    # Enable command line auto-complete support
    argcomplete.autocomplete(parser)

    # Parse the arguments
    cmd_line_args = parser.parse_args()

    # Build our log format
    log_format = ''

    # If we have command line option to turn on timestamps, they are first
    if cmd_line_args.log_timestamps:
        log_format += '%(asctime)s\t'

    # If we have a log prefix, add that
    if cmd_line_args.log_prefix:
        log_format += '{0}\t'.format(cmd_line_args.log_prefix)

    # Our normal format:  the log level and then the message
    log_format += '%(levelname)s: %(message)s'

    # Set our logging level and output format
    logging.basicConfig(level=cmd_line_args.log_level, format=log_format)

    # and call the appropriate function
    cmd_line_args.func(cmd_line_args)


# ======================= Entry point =======================
if __name__ == "__main__":
    main()
