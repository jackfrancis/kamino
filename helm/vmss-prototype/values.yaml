# Some default values for the Kamino VMSS-Prototype Pattern Image Generator

kamino:
  name: kamino-gen
  labels:
    app: kamino-vmss-prototype
  container:
    # TODO:  Point these to our public container registry once we have it setup
    imageRegistry: ghcr.io
    imageRepository: jackfrancis/kamino/vmss-prototype
    imageTag: v0.0.6
    # Pulling by hash has stronger assurance that the container is unchanged
    imageHash: "d154002ee4db8ca691357b7cc7ceb864d3e00f67a8a1be5554d749469d609c3f"
    pullByHash: true

    # include the name of the image pull secret in your cluster if you
    # need one.  (Note that they are local to the namespace you deploy in)
    #pullSecret: skyman-acr

  # Number of images to keep in the history
  # Minimum is 2.
  imageHistory: 3

  drain:
    # Drain grace period is the maximum time to allow pods to drain load
    # and leave the node.  The default of 300 seconds is relatively long
    # but extra safe.
    gracePeriod: 300

    # Drain Force, if set to true, will force drain the node if the normal
    # drain fails to drain the node.  This may be needed if the drain operation
    # is not respected by the workloads in the cluster.
    force: false

  auto:
    # This is the minimum amount of time a node needs to be ready before it
    # is considered "good"
    # Number of seconds or with single character suffix for seconds, minutes,
    # hours, or days
    #  3s == 3 seconds
    #  3m == 3 minutes
    #  3h == 3 hours
    #  3d == 3 days
    # We pick a default of 1h (1 hour)
    minimumReadyTime: 1h

    # The minimum number of valide candidates before we consider that we
    # have enough signal to pick one of them.  The default is 1 as you must
    # have 1 candidate but large critical clusters you may wish to wait
    # until you have a number of nodes that have taken the updates and are
    # in ready state before you commit to picking one of them as a good
    # candidate.
    minimumCandidates: 1

    # The maximum age of the current VMSS Prototype image before the auto
    # node selection logic will try to find a new candate even if there
    # has been no OS update/patch.  If set to 0, this no age is defined
    # and thus the age is never considered.  Otherwise it is the number
    # of days in age of the current image.  For example, if set to 7 days,
    # once the current VMSS Prototype image is over 7 days old, the auto
    # node selection process will not limit its node selection only to nodes
    # that have an OS update/patch that is newer than the prior image.
    # OS Updates/patches are always preferred but if the age is over the
    # limit, an OS update/patch is not required.
    maximumImageAge: 0

    # The annotation on a node that holds the last time a patch was
    # "applied"
    #lastPatchAnnotation: weave.works/kured-most-recent-reboot-needed

    # If this annotation exists, we do not want the node as it is
    # pending a servicing reboot.  We don't want pending reboot nodes
    #pendingRebootAnnotation: weave.works/kured-reboot-in-progress

    dryRun: false

  # This is the log-level for the process via python logging.
  # Each level includes all below it, so DEBUG includes INFO, WARNING, etc...
  # Best keep this at INFO

  # DEBUG    - Very verbose (albeit not that much more than INFO)
  # INFO     - Show all process executions and actions as progress
  # WARNING  - Show only the warnings
  # ERROR    - Show only the errors
  # CRITICAL - Show only complete critical faults
  logLevel: INFO

  # The the target node are not things we can know
  # automatically
  #targetNode: k8s-agentpool1-12345678-vmss0001ct

  # The target VMSS to use, or "ALL" for automatically doing all of them
  # Only useful if you don't have a targetNode
  #targetVMSS: k8s-agentpool1-12345678-vmss
  #targetVMSS: ALL

  # Set newUpdatedNodes to a higher value to immediately add more nodes built from the prototype after VMSS update is complete
  newUpdatedNodes: 0

  # Require scheduling the pod onto a control plane VM using the AKS Engine control plane VM identifier
  # Default to false, which allows scheduling on any node other than the targetNode
  scheduleOnControlPlane: false
